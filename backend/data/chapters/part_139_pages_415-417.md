# Embedding Artificial Intelligence into ERP Software A Conceptual View on Business AI with Examples from SAP S4HANA (Siar Sarferaz) (z-library.sk, 1lib.sk, z-lib.sk) - ç¬¬139éƒ¨åˆ†

**åŸå§‹é¡µç **: 415 - 417
**æ®µè½æ•°é‡**: 37
**ç¿»è¯‘å·¥å…·**: Claude Code CLI

## ğŸ“– ç¿»è¯‘ç­–ç•¥å’Œä¸Šä¸‹æ–‡ä¿¡æ¯

- **ä½¿ç”¨çš„ç¿»è¯‘ç­–ç•¥**: å®Œæ•´ä¸Šä¸‹æ–‡
- **å‰æ–‡ä¸Šä¸‹æ–‡é¡µç **: 414-414 (3505 å­—ç¬¦)
- **åæ–‡ä¸Šä¸‹æ–‡é¡µç **: 418-418 (3174 å­—ç¬¦)

*æ³¨ï¼šç¿»è¯‘æ—¶å·²ä½¿ç”¨"å®Œæ•´ä¸Šä¸‹æ–‡"ç­–ç•¥ï¼Œå‚è€ƒå‰åæ–‡ä¸Šä¸‹æ–‡ä»¥ç¡®ä¿æœ¯è¯­ä¸€è‡´æ€§å’Œå†…å®¹è¿è´¯æ€§*

**æœ¯è¯­è¯´æ˜**: 1. Human Agency (äººç±»è‡ªä¸»æƒ): å¼ºè°ƒäººåœ¨ä¸AIäº¤äº’æ—¶ä¿æŒæ§åˆ¶å’Œé€‰æ‹©çš„èƒ½åŠ›ã€‚ 2. Human-in-the-loop/on-the-loop (äººåœ¨å›è·¯/äººåœ¨ç›‘è·¯): ä¸šç•Œæ ‡å‡†æœ¯è¯­ï¼Œåˆ†åˆ«æŒ‡äººç›´æ¥å‚ä¸å†³ç­–å’Œäººè¿›è¡Œç›‘ç£ä½†ä¸ä¸€å®šç›´æ¥å¹²é¢„ã€‚ 3. Fairness function (å…¬å¹³æ€§å‡½æ•°): æœºå™¨å­¦ä¹ ä¸­ç”¨äºæ•°å­¦åŒ–è¡¡é‡ç®—æ³•å…¬å¹³æ€§çš„æŒ‡æ ‡æˆ–å‡½æ•°ã€‚ 4. De-anonymize (å»åŒ¿ååŒ–): æŒ‡ä»åŒ¿åæ•°æ®ä¸­æ¢å¤ä¸ªäººèº«ä»½çš„è¿‡ç¨‹ã€‚

---

use and that the product requirements are met. To maintain and further enhance the quality, safety, reliability, and security of our systems, we collaborate closely with our clients and users.

**ã€è¯‘æ–‡ã€‘** ï¼ˆæ‰¿æ¥å‰æ–‡â€¦â€¦ï¼‰ç”¨é€”ï¼Œå¹¶ç¡®ä¿æ»¡è¶³äº§å“éœ€æ±‚ã€‚ä¸ºäº†ä¿æŒå¹¶è¿›ä¸€æ­¥å¢å¼ºæˆ‘ä»¬ç³»ç»Ÿçš„è´¨é‡ã€å®‰å…¨æ€§ã€å¯é æ€§å’Œä¿éšœæ€§ï¼Œæˆ‘ä»¬ä¸å®¢æˆ·åŠç”¨æˆ·ç´§å¯†åˆä½œã€‚

---

â€¢ Place data protection and privacy at the core: Every product and service must include data protection and privacy as a basic component. We are transparent about the how, why, where, and when our artificial intelligence software uses customer and anonymized user data. This dedication to data security and privacy is shown in our compliance with all relevant legal standards as well as in the research we carry out in collaboration with top academic institutions to create the newest approaches and tools for strengthening privacy.

**ã€è¯‘æ–‡ã€‘** â€¢ ä»¥æ•°æ®ä¿æŠ¤å’Œéšç§ä¸ºæ ¸å¿ƒï¼šæ¯ä¸ªäº§å“å’ŒæœåŠ¡éƒ½å¿…é¡»åŒ…å«æ•°æ®ä¿æŠ¤å’Œéšç§ä½œä¸ºåŸºæœ¬è¦ç´ ã€‚æˆ‘ä»¬å¯¹äººå·¥æ™ºèƒ½è½¯ä»¶å¦‚ä½•ã€ä¸ºä½•ã€ä½•åœ°ä»¥åŠä½•æ—¶ä½¿ç”¨å®¢æˆ·å’ŒåŒ¿åç”¨æˆ·æ•°æ®ä¿æŒé€æ˜ã€‚è¿™ç§å¯¹æ•°æ®å®‰å…¨å’Œéšç§çš„æ‰¿è¯ºï¼Œä½“ç°åœ¨æˆ‘ä»¬è¦éµå®ˆæ‰€æœ‰ç›¸å…³æ³•å¾‹æ ‡å‡†ï¼Œä»¥åŠæˆ‘ä»¬ä¸é¡¶å°–å­¦æœ¯æœºæ„åˆä½œè¿›è¡Œçš„ç ”ç©¶ä¸­ï¼Œæ—¨åœ¨å¼€å‘åŠ å¼ºéšç§ä¿æŠ¤çš„æœ€æ–°æ–¹æ³•å’Œå·¥å…·ã€‚

---

â€¢ Engage with the wider societal challenges of artificial intelligence: The aforementioned areas are mostly under our control, but there are a number of new concerns that call for a much wider conversation that cuts across fields, countries, and cultural, philosophical, and religious traditions. These include, but are not restricted to, inquiries about:

**ã€è¯‘æ–‡ã€‘** â€¢ åº”å¯¹äººå·¥æ™ºèƒ½å¸¦æ¥çš„æ›´å¹¿æ³›ç¤¾ä¼šæŒ‘æˆ˜ï¼šä¸Šè¿°é¢†åŸŸä¸»è¦åœ¨æˆ‘ä»¬çš„æ§åˆ¶ä¹‹ä¸‹ï¼Œä½†æœ‰è®¸å¤šæ–°é—®é¢˜éœ€è¦è·¨é¢†åŸŸã€è·¨å›½å®¶ä»¥åŠè·¨æ–‡åŒ–ã€å“²å­¦å’Œå®—æ•™ä¼ ç»Ÿè¿›è¡Œæ›´å¹¿æ³›çš„å¯¹è¯ã€‚è¿™äº›åŒ…æ‹¬ä½†ä¸é™äºä»¥ä¸‹ç–‘é—®ï¼š

---

â€“â€“ Impact on the economy, including how business and society should work together to prepare students and workers for an AI economy and how society may need to change how it distributes wealth, ensures social safety, and develops its economy.

**ã€è¯‘æ–‡ã€‘** â€“â€“ å¯¹ç»æµçš„å½±å“ï¼ŒåŒ…æ‹¬ä¼ä¸šå’Œç¤¾ä¼šåº”å¦‚ä½•åä½œï¼Œè®©å­¦ç”Ÿå’Œå·¥äººä¸ºAIç»æµåšå¥½å‡†å¤‡ï¼Œä»¥åŠç¤¾ä¼šå¯èƒ½éœ€è¦å¦‚ä½•æ”¹å˜è´¢å¯Œåˆ†é…æ–¹å¼ã€ä¿éšœç¤¾ä¼šå®‰å…¨å’Œå‘å±•ç»æµã€‚

---

â€“â€“ Impact on society, including the worth and significance of labor for individuals and the potential for AI programs to serve as social companions and caregivers.

**ã€è¯‘æ–‡ã€‘** â€“â€“ å¯¹ç¤¾ä¼šçš„å½±å“ï¼ŒåŒ…æ‹¬åŠ³åŠ¨å¯¹ä¸ªäººçš„ä»·å€¼å’Œæ„ä¹‰ï¼Œä»¥åŠAIç¨‹åºä½œä¸ºç¤¾ä¼šä¼´ä¾£å’ŒæŠ¤ç†è€…çš„æ½œåŠ›ã€‚

---

â€“â€“ Normative issues include how artificial intelligence should handle moral conundrums and what uses of artificial intelligence, particularly in terms of security and safety, should be regarded acceptable.

**ã€è¯‘æ–‡ã€‘** â€“â€“ ä¼¦ç†è§„èŒƒé—®é¢˜ï¼ŒåŒ…æ‹¬äººå·¥æ™ºèƒ½åº”å¦‚ä½•å¤„ç†é“å¾·å›°å¢ƒï¼Œä»¥åŠäººå·¥æ™ºèƒ½çš„å“ªäº›ç”¨é€”ï¼ˆç‰¹åˆ«æ˜¯åœ¨å®‰é˜²å’Œå®‰å…¨æ–¹é¢ï¼‰åº”è¢«è§†ä¸ºå¯æ¥å—çš„ã€‚

---

In addition, there are further challenges that require a much broader discourse across industries, disciplines, borders, and cultural, philosophical, and religious traditions.

**ã€è¯‘æ–‡ã€‘** æ­¤å¤–ï¼Œè¿˜æœ‰æ›´å¤šæŒ‘æˆ˜éœ€è¦åœ¨è¡Œä¸šã€å­¦ç§‘ã€å›½ç•Œä»¥åŠæ–‡åŒ–ã€å“²å­¦å’Œå®—æ•™ä¼ ç»Ÿä¹‹é—´è¿›è¡Œæ›´å¹¿æ³›çš„æ¢è®¨ã€‚

---

25.2 Ethics Policy

**ã€è¯‘æ–‡ã€‘** 25.2 ä¼¦ç†æ”¿ç­–

---

In this section, the guiding principles for artificial intelligence are explained in further detail in the ethics policy (SAP AI Ethics Policy, 2022). Particularly, the AI ethics policy clarifies how the guiding principles are related to artificial intelligence use cases. It outlines the objectives, requirements, and responsibilities for staff members involved in the creation, use, and sale of artificial intelligence business applications.

**ã€è¯‘æ–‡ã€‘** åœ¨æœ¬èŠ‚ä¸­ï¼Œäººå·¥æ™ºèƒ½çš„æŒ‡å¯¼åŸåˆ™å°†åœ¨ä¼¦ç†æ”¿ç­–ï¼ˆSAP AI Ethics Policy, 2022ï¼‰ä¸­å¾—åˆ°æ›´è¯¦ç»†çš„è§£é‡Šã€‚ç‰¹åˆ«æ˜¯ï¼ŒAIä¼¦ç†æ”¿ç­–é˜æ˜äº†æŒ‡å¯¼åŸåˆ™å¦‚ä½•ä¸äººå·¥æ™ºèƒ½ç”¨ä¾‹ç›¸å…³è”ã€‚å®ƒæ¦‚è¿°äº†å‚ä¸åˆ›å»ºã€ä½¿ç”¨å’Œé”€å”®äººå·¥æ™ºèƒ½å•†ä¸šåº”ç”¨çš„å‘˜å·¥çš„ç›®æ ‡ã€è¦æ±‚å’Œè´£ä»»ã€‚

---

25.2.1 Human Agency and Oversight

**ã€è¯‘æ–‡ã€‘** 25.2.1 äººç±»è‡ªä¸»æƒä¸ç›‘ç£

---

Teams should take into account the following when developing artificial intelligence business applications as they relate to Human Agency and Oversight:

**ã€è¯‘æ–‡ã€‘** å›¢é˜Ÿåœ¨å¼€å‘æ¶‰åŠâ€œäººç±»è‡ªä¸»æƒä¸ç›‘ç£â€çš„äººå·¥æ™ºèƒ½å•†ä¸šåº”ç”¨æ—¶ï¼Œåº”è€ƒè™‘ä»¥ä¸‹å‡ ç‚¹ï¼š

---

â€¢ A humanâ€™s rights and freedoms should always outweigh those of an artificial intelligence business application, with the exception of situations when it is expressly permitted by local laws that are in force.

**ã€è¯‘æ–‡ã€‘** â€¢ äººç±»çš„æƒåˆ©å’Œè‡ªç”±åº”å§‹ç»ˆé«˜äºäººå·¥æ™ºèƒ½å•†ä¸šåº”ç”¨ï¼Œé™¤éå½“åœ°ç°è¡Œæ³•å¾‹æ˜ç¡®å…è®¸ã€‚

---

â€¢ When applicable local law is silent, human oversight must be accomplished by means of an effective governance system. This will be determined on a case-by-case basis and may include, but not be limited to, human-in-the-loop, human-on-the-loop, or human-in-command.

**ã€è¯‘æ–‡ã€‘** â€¢ å½“é€‚ç”¨çš„å½“åœ°æ³•å¾‹æ²¡æœ‰è§„å®šæ—¶ï¼Œå¿…é¡»é€šè¿‡æœ‰æ•ˆçš„æ²»ç†ä½“ç³»æ¥å®ç°äººç±»ç›‘ç£ã€‚è¿™å°†æ ¹æ®å…·ä½“æƒ…å†µå†³å®šï¼Œå¯èƒ½åŒ…æ‹¬ä½†ä¸é™äºâ€œäººåœ¨å›è·¯â€ï¼ˆhuman-in-the-loopï¼‰ã€â€œäººåœ¨ç›‘è·¯â€ï¼ˆhuman-on-the-loopï¼‰æˆ–â€œäººç±»æŒæ§â€ï¼ˆhuman-in-commandï¼‰ã€‚

---

â€¢ In accordance with the data privacy and protection policy of an enterprise, human oversight must be implemented in cases where humans may be directly impacted by a decision made by artificial intelligence business applications to ensure that it does not compromise human autonomy or have unexpected effects.

**ã€è¯‘æ–‡ã€‘** â€¢ æ ¹æ®ä¼ä¸šçš„æ•°æ®éšç§å’Œä¿æŠ¤æ”¿ç­–ï¼Œåœ¨äººç±»å¯èƒ½ç›´æ¥å—åˆ°äººå·¥æ™ºèƒ½å•†ä¸šåº”ç”¨å†³ç­–å½±å“çš„æƒ…å†µä¸‹ï¼Œå¿…é¡»å®æ–½äººç±»ç›‘ç£ï¼Œä»¥ç¡®ä¿ä¸æŸå®³äººç±»è‡ªä¸»æƒæˆ–äº§ç”Ÿæ„å¤–åæœã€‚

---

â€¢ As much as is practicable, an explanation of how decisions were made by an artificial intelligence business application utilized in automated decision processes must be given.

**ã€è¯‘æ–‡ã€‘** â€¢ å¿…é¡»åœ¨åˆ‡å®å¯è¡Œçš„æƒ…å†µä¸‹ï¼Œå¯¹ç”¨äºè‡ªåŠ¨åŒ–å†³ç­–è¿‡ç¨‹çš„äººå·¥æ™ºèƒ½å•†ä¸šåº”ç”¨å¦‚ä½•åšå‡ºå†³ç­–æä¾›è§£é‡Šã€‚

---

â€¢ To ensure the artificial intelligence business application behaves as intended by the developers and does not have any unintended behavior, outputs, or usage, appropriate extensive testing and governance shall be conducted during development and deployment where the visibility of human oversight of the artificial intelligence system may be limited or unknown after deployment.

**ã€è¯‘æ–‡ã€‘** â€¢ ä¸ºäº†ç¡®ä¿äººå·¥æ™ºèƒ½å•†ä¸šåº”ç”¨çš„è¡¨ç°ç¬¦åˆå¼€å‘è€…çš„é¢„æœŸï¼Œä¸”ä¸å‡ºç°ä»»ä½•æ„å¤–çš„è¡Œä¸ºã€è¾“å‡ºæˆ–ä½¿ç”¨æ–¹å¼ï¼Œå¦‚æœéƒ¨ç½²åå¯¹äººå·¥æ™ºèƒ½ç³»ç»Ÿçš„äººç±»ç›‘ç£å¯è§æ€§å¯èƒ½å—é™æˆ–æœªçŸ¥ï¼Œåˆ™å¿…é¡»åœ¨å¼€å‘å’Œéƒ¨ç½²æœŸé—´è¿›è¡Œé€‚å½“çš„å¹¿æ³›æµ‹è¯•å’Œæ²»ç†ã€‚

---

25.2.2 Addressing Bias and Discrimination

**ã€è¯‘æ–‡ã€‘** 25.2.2 è§£å†³åè§ä¸æ­§è§†

---

Artificial intelligence systems learn from the behaviors and existing social structures of the cultures they study. Therefore, data-driven technologies have the potential to replicate, reinforce, and magnify societal patterns of marginalization, inequality, and prejudice that may be embedded in data sources utilized to develop artificial intelligence.

**ã€è¯‘æ–‡ã€‘** äººå·¥æ™ºèƒ½ç³»ç»Ÿä»å…¶ç ”ç©¶æ–‡åŒ–çš„è¡Œä¸ºå’Œç°æœ‰ç¤¾ä¼šç»“æ„ä¸­å­¦ä¹ ã€‚å› æ­¤ï¼Œæ•°æ®é©±åŠ¨çš„æŠ€æœ¯æœ‰å¯èƒ½å¤åˆ¶ã€å¼ºåŒ–å’Œæ”¾å¤§é‚£äº›å¯èƒ½åµŒå…¥åœ¨ç”¨äºå¼€å‘äººå·¥æ™ºèƒ½çš„æ•°æ®æºä¸­çš„è¾¹ç¼˜åŒ–ã€ä¸å¹³ç­‰å’Œåè§çš„ç¤¾ä¼šæ¨¡å¼ã€‚

---

In addition, artificial intelligence business applications may be able to reproduce the prejudices and preconceptions of its developers as many of the characteristics, metrics, and analytical frameworks of the models that enable data mining are chosen by their creators.

**ã€è¯‘æ–‡ã€‘** æ­¤å¤–ï¼Œäººå·¥æ™ºèƒ½å•†ä¸šåº”ç”¨å¯èƒ½ä¼šå†ç°å…¶å¼€å‘è€…çš„åè§å’Œæˆè§ï¼Œå› ä¸ºæ”¯æŒæ•°æ®æŒ–æ˜çš„æ¨¡å‹çš„è®¸å¤šç‰¹å¾ã€æŒ‡æ ‡å’Œåˆ†ææ¡†æ¶éƒ½æ˜¯ç”±åˆ›å»ºè€…é€‰æ‹©çš„ã€‚

---

Finally, data samples utilized to develop algorithmic systemsâ€™ training and testing processes may not be properly representative of the populations or historical contexts from which they are inferring conclusions. This may apply in situations when the initial datasets were collected from businesses, industries, or other organizations that are inappropriate for the artificial intelligence business application being created and implemented.

**ã€è¯‘æ–‡ã€‘** æœ€åï¼Œç”¨äºå¼€å‘ç®—æ³•ç³»ç»Ÿè®­ç»ƒå’Œæµ‹è¯•è¿‡ç¨‹çš„æ•°æ®æ ·æœ¬ï¼Œå¯èƒ½æ— æ³•æ°å½“åœ°ä»£è¡¨æ¨å¯¼ç»“è®ºæ‰€ä¾æ®çš„äººç¾¤æˆ–å†å²èƒŒæ™¯ã€‚è¿™ç§æƒ…å†µå¯èƒ½é€‚ç”¨äºåˆå§‹æ•°æ®é›†æ˜¯ä»å¯¹äºæ­£åœ¨åˆ›å»ºå’Œå®æ–½çš„AIå•†ä¸šåº”ç”¨ä¸é€‚ç”¨çš„ä¼ä¸šã€è¡Œä¸šæˆ–å…¶ä»–ç»„ç»‡æ”¶é›†è€Œæ¥çš„æƒ…å½¢ã€‚

---

These biases may have a negative effect on the creation and results of artificial intelligence business applications, which may therefore have an adverse effect on users or clients. When there is a chance of fostering discrimination or unfairly affecting underrepresented groups, extra caution must be exercised.

**ã€è¯‘æ–‡ã€‘** è¿™äº›åè§å¯èƒ½ä¼šå¯¹äººå·¥æ™ºèƒ½å•†ä¸šåº”ç”¨çš„åˆ›å»ºå’Œç»“æœäº§ç”Ÿè´Ÿé¢å½±å“ï¼Œä»è€Œå¯¹ç”¨æˆ·æˆ–å®¢æˆ·äº§ç”Ÿä¸åˆ©å½±å“ã€‚å½“å­˜åœ¨åŠ©é•¿æ­§è§†æˆ–ä¸å…¬å¹³åœ°å½±å“ä»£è¡¨æ€§ä¸è¶³ç¾¤ä½“çš„é£é™©æ—¶ï¼Œå¿…é¡»æ ¼å¤–è°¨æ…ã€‚

---

As it relates to resolving bias and discrimination in artificial intelligence systems, teams need to take the following into account:

**ã€è¯‘æ–‡ã€‘** å…³äºè§£å†³äººå·¥æ™ºèƒ½ç³»ç»Ÿä¸­çš„åè§å’Œæ­§è§†é—®é¢˜ï¼Œå›¢é˜Ÿéœ€è¦è€ƒè™‘ä»¥ä¸‹å‡ ç‚¹ï¼š

---

â€¢ In addition to the restrictions outlined by the data privacy and protection policy of enterprises, artificial intelligence systems must not be created or used to de-anonymize data that has previously been anonymized in a way that could lead to the identification of certain people or groups.

**ã€è¯‘æ–‡ã€‘** â€¢ é™¤äº†ä¼ä¸šæ•°æ®éšç§å’Œä¿æŠ¤æ”¿ç­–ä¸­æ¦‚è¿°çš„é™åˆ¶å¤–ï¼Œä¸å¾—åˆ›å»ºæˆ–ä½¿ç”¨äººå·¥æ™ºèƒ½ç³»ç»Ÿæ¥å¯¹å…ˆå‰å·²åŒ¿ååŒ–çš„æ•°æ®è¿›è¡Œå»åŒ¿ååŒ–ï¼ˆde-anonymizeï¼‰ï¼Œä»è€Œå¯¼è‡´ç‰¹å®šäººå‘˜æˆ–ç¾¤ä½“è¢«è¯†åˆ«ã€‚

---

â€¢ Artificial intelligence business applications must not purposefully produce unfairly skewed results.

**ã€è¯‘æ–‡ã€‘** â€¢ äººå·¥æ™ºèƒ½å•†ä¸šåº”ç”¨ä¸å¾—æ•…æ„äº§ç”Ÿä¸å…¬å¹³çš„å€¾æ–œç»“æœã€‚

---

â€¢ The data used to train artificial intelligence systems must, where applicable, be as inclusive as possible, represent a diverse cross-section of the population or historical events, and be as free as possible from any historical or socially constructed biases, inaccuracies, errors, and mistakes (or account for and mitigate them).

**ã€è¯‘æ–‡ã€‘** â€¢ ç”¨äºè®­ç»ƒäººå·¥æ™ºèƒ½ç³»ç»Ÿçš„æ•°æ®å¿…é¡»åœ¨é€‚ç”¨æƒ…å†µä¸‹å°½å¯èƒ½å…·æœ‰åŒ…å®¹æ€§ï¼Œä»£è¡¨äººå£æˆ–å†å²äº‹ä»¶çš„å¤šæ ·åŒ–æˆªé¢ï¼Œå¹¶å°½å¯èƒ½é¿å…ä»»ä½•å†å²æˆ–ç¤¾ä¼šæ„å»ºçš„åè§ã€ä¸å‡†ç¡®ã€é”™è¯¯å’Œå¤±è¯¯ï¼ˆæˆ–å¯¹å…¶è¿›è¡Œè¯´æ˜å’Œç¼“è§£ï¼‰ã€‚

---

â€¢ In order to minimize direct or indirect prejudice, discrimination, or marginalization of groups or individuals, teams must make an effort to identify unfairly biased outputs and take technological or organizational remedies, such as minimizing bias in training data.

**ã€è¯‘æ–‡ã€‘** â€¢ ä¸ºäº†æœ€å¤§é™åº¦åœ°å‡å°‘å¯¹ç¾¤ä½“æˆ–ä¸ªäººçš„ç›´æ¥æˆ–é—´æ¥åè§ã€æ­§è§†æˆ–è¾¹ç¼˜åŒ–ï¼Œå›¢é˜Ÿå¿…é¡»åŠªåŠ›è¯†åˆ«ä¸å…¬å¹³çš„åè§è¾“å‡ºï¼Œå¹¶é‡‡å–æŠ€æœ¯æˆ–ç»„ç»‡è¡¥æ•‘æªæ–½ï¼Œä¾‹å¦‚æœ€å¤§é™åº¦åœ°å‡å°‘è®­ç»ƒæ•°æ®ä¸­çš„åè§ã€‚

---

â€¢ Developers must make every effort to include impacted/affected users when evaluating and verifying that outputs are inclusive and devoid of discrimination.

**ã€è¯‘æ–‡ã€‘** â€¢ åœ¨è¯„ä¼°å’ŒéªŒè¯è¾“å‡ºç»“æœæ˜¯å¦å…·æœ‰åŒ…å®¹æ€§ä¸”ä¸å­˜åœ¨æ­§è§†æ—¶ï¼Œå¼€å‘è€…å¿…é¡»å°½ä¸€åˆ‡åŠªåŠ›å°†å—å½±å“çš„ç”¨æˆ·çº³å…¥å…¶ä¸­ã€‚

---

â€¢ Processes must be in place to test and monitor for potential biases during the development, implementation, and use phase of artificial intelligence business applications.

**ã€è¯‘æ–‡ã€‘** â€¢ å¿…é¡»å»ºç«‹ç›¸åº”æµç¨‹ï¼Œåœ¨äººå·¥æ™ºèƒ½å•†ä¸šåº”ç”¨çš„å¼€å‘ã€å®æ–½å’Œä½¿ç”¨é˜¶æ®µæµ‹è¯•å¹¶ç›‘æ§æ½œåœ¨çš„åè§ã€‚

---

â€“â€“ It must be trained and evaluated using datasets that are as large, representative, accurate, and generalizable as is practical.

**ã€è¯‘æ–‡ã€‘** â€“â€“ å¿…é¡»ä½¿ç”¨å°½å¯èƒ½å¤§ã€å…·æœ‰ä»£è¡¨æ€§ã€å‡†ç¡®ä¸”å¯æ³›åŒ–çš„æ•°æ®é›†å¯¹å…¶è¿›è¡Œè®­ç»ƒå’Œè¯„ä¼°ã€‚

---

â€“â€“ Target variables, characteristics, procedures, or analytic structures that are irrational, unethical, or impossible to validate in accordance with the guiding principles shall not be included in the model architectures.

**ã€è¯‘æ–‡ã€‘** â€“â€“ ä¸å¾—å°†ä¸åˆç†ã€ä¸é“å¾·æˆ–æ— æ³•æ ¹æ®æŒ‡å¯¼åŸåˆ™è¿›è¡ŒéªŒè¯çš„ç›®æ ‡å˜é‡ã€ç‰¹å¾ã€ç¨‹åºæˆ–åˆ†æç»“æ„åŒ…å«åœ¨æ¨¡å‹æ¶æ„ä¸­ã€‚

---

â€“â€“ It must be created and implemented without having any unintentionally negative effects on system users or any direct or indirect beneficiaries.

**ã€è¯‘æ–‡ã€‘** â€“â€“ å…¶åˆ›å»ºå’Œå®æ–½ä¸å¾—å¯¹ç³»ç»Ÿç”¨æˆ·æˆ–ä»»ä½•ç›´æ¥æˆ–é—´æ¥å—ç›Šäººäº§ç”Ÿä»»ä½•æ„å¤–çš„è´Ÿé¢å½±å“ã€‚

---

â€“â€“ A fairness function should be used to assess artificial intelligence systems for impartial results where it is practical to do so.

**ã€è¯‘æ–‡ã€‘** â€“â€“ åœ¨åˆ‡å®å¯è¡Œçš„æƒ…å†µä¸‹ï¼Œåº”ä½¿ç”¨å…¬å¹³æ€§å‡½æ•°ï¼ˆfairness functionï¼‰æ¥è¯„ä¼°äººå·¥æ™ºèƒ½ç³»ç»Ÿï¼Œä»¥ç¡®ä¿ç»“æœå…¬æ­£ã€‚

---

â€¢ Regardless of the usersâ€™ age, gender, abilities, or traits, artificial intelligence business applications must be user-centric, addressing the broadest variety of relevant end users and adhering to pertinent accessibility requirements.

**ã€è¯‘æ–‡ã€‘** â€¢ æ— è®ºç”¨æˆ·çš„å¹´é¾„ã€æ€§åˆ«ã€èƒ½åŠ›æˆ–ç‰¹å¾å¦‚ä½•ï¼Œäººå·¥æ™ºèƒ½å•†ä¸šåº”ç”¨éƒ½å¿…é¡»ä»¥ç”¨æˆ·ä¸ºä¸­å¿ƒï¼Œè¦†ç›–æœ€å¹¿æ³›çš„ç›¸å…³æœ€ç»ˆç”¨æˆ·ç¾¤ä½“ï¼Œå¹¶éµå®ˆç›¸å…³çš„æ— éšœç¢è¦æ±‚ã€‚

---

25.2.3 Transparency and Explainability

**ã€è¯‘æ–‡ã€‘** 25.2.3 é€æ˜åº¦ä¸å¯è§£é‡Šæ€§

---

In accordance with their level of technical expertise and intended use, artificial intelligence business applications are subject to strict requirements. Along with the technical resources required for training and prediction, we must effectively express to clients their input, capabilities, intended use, and restrictions.

**ã€è¯‘æ–‡ã€‘** æ ¹æ®æŠ€æœ¯ä¸“é•¿æ°´å¹³å’Œé¢„æœŸç”¨é€”ï¼Œäººå·¥æ™ºèƒ½å•†ä¸šåº”ç”¨é¡»éµå®ˆä¸¥æ ¼çš„è¦æ±‚ã€‚é™¤äº†è®­ç»ƒå’Œé¢„æµ‹æ‰€éœ€çš„æŠ€æœ¯èµ„æºå¤–ï¼Œæˆ‘ä»¬å¿…é¡»å‘å®¢æˆ·æœ‰æ•ˆä¼ è¾¾å…¶è¾“å…¥ã€èƒ½åŠ›ã€é¢„æœŸç”¨é€”å’Œé™åˆ¶ã€‚

---

Since artificial intelligence agents lack moral accountability, it is impossible to hold them responsible for their deeds. By prioritizing both the transparency of the process by which the artificial intelligence business application is built and the transparency and interpretability of its decisions and behaviors, procedures must be put in place to ensure that developed artificial intelligence systems are objective and viable as planned.

**ã€è¯‘æ–‡ã€‘** ç”±äºäººå·¥æ™ºèƒ½ä»£ç†ç¼ºä¹é“å¾·è´£ä»»æ„Ÿï¼Œå› æ­¤æ— æ³•è®©å…¶å¯¹è‡ªå·±çš„è¡Œä¸ºè´Ÿè´£ã€‚é€šè¿‡ä¼˜å…ˆè€ƒè™‘äººå·¥æ™ºèƒ½å•†ä¸šåº”ç”¨æ„å»ºè¿‡ç¨‹çš„é€æ˜åº¦ï¼Œä»¥åŠå…¶å†³ç­–å’Œè¡Œä¸ºçš„é€æ˜åº¦å’Œå¯è§£é‡Šæ€§ï¼Œå¿…é¡»å»ºç«‹ç›¸åº”ç¨‹åºï¼Œä»¥ç¡®ä¿æ‰€å¼€å‘çš„äººå·¥æ™ºèƒ½ç³»ç»Ÿå®¢è§‚ä¸”æŒ‰è®¡åˆ’å¯è¡Œã€‚

---

As it relates to the transparency and explainability of artificial intelligence business applications, teams should take the following into account:

**ã€è¯‘æ–‡ã€‘** å…³äºäººå·¥æ™ºèƒ½å•†ä¸šåº”ç”¨çš„é€æ˜åº¦å’Œå¯è§£é‡Šæ€§ï¼Œå›¢é˜Ÿåº”è€ƒè™‘ä»¥ä¸‹å‡ ç‚¹ï¼š

---

