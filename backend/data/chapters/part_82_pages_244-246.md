# Embedding Artificial Intelligence into ERP Software A Conceptual View on Business AI with Examples from SAP S4HANA (Siar Sarferaz) (z-library.sk, 1lib.sk, z-lib.sk) - ç¬¬82éƒ¨åˆ†

**åŸå§‹é¡µç **: 244 - 246
**æ®µè½æ•°é‡**: 26
**ç¿»è¯‘å·¥å…·**: Claude Code CLI

## ğŸ“– ç¿»è¯‘ç­–ç•¥å’Œä¸Šä¸‹æ–‡ä¿¡æ¯

- **ä½¿ç”¨çš„ç¿»è¯‘ç­–ç•¥**: å®Œæ•´ä¸Šä¸‹æ–‡
- **å‰æ–‡ä¸Šä¸‹æ–‡é¡µç **: 243-243 (1335 å­—ç¬¦)
- **åæ–‡ä¸Šä¸‹æ–‡é¡µç **: 247-247 (3363 å­—ç¬¦)

*æ³¨ï¼šç¿»è¯‘æ—¶å·²ä½¿ç”¨"å®Œæ•´ä¸Šä¸‹æ–‡"ç­–ç•¥ï¼Œå‚è€ƒå‰åæ–‡ä¸Šä¸‹æ–‡ä»¥ç¡®ä¿æœ¯è¯­ä¸€è‡´æ€§å’Œå†…å®¹è¿è´¯æ€§*

**æœ¯è¯­è¯´æ˜**: 1. Side-by-Side: è¯‘ä¸ºâ€œå¹¶è¡Œâ€ï¼Œå¯¹åº” ERP è¯­å¢ƒä¸‹çš„ Side-by-Side Extensibilityï¼ˆå¹¶è¡Œæ‰©å±•ï¼‰ã€‚
2. Workload class: è¯‘ä¸ºâ€œå·¥ä½œè´Ÿè½½ç±»â€ï¼ŒHANA æ•°æ®åº“æ ‡å‡†æœ¯è¯­ã€‚
3. Pod/Chart: Kubernetes å’Œ Helm çš„ä¸“ç”¨æœ¯è¯­ï¼Œä¿ç•™è‹±æ–‡æˆ–ä½¿ç”¨ä¸šç•Œé€šç”¨ä¸­æ–‡æƒ¯ä¾‹ã€‚

---

Fig. 15.3â€‚ Workload classes for embedded artificial intelligence
and mapping technology. The aim of workload class and mapping is to prevent the 
overuse of system resources like CPU time and memory by applying predefined 
mapping rules. This process generally involves the following steps:

**ã€è¯‘æ–‡ã€‘** å›¾ 15.3 åµŒå…¥å¼äººå·¥æ™ºèƒ½çš„å·¥ä½œè´Ÿè½½ç±»å’Œæ˜ å°„æŠ€æœ¯ã€‚å·¥ä½œè´Ÿè½½ç±»å’Œæ˜ å°„çš„ç›®æ ‡æ˜¯é€šè¿‡åº”ç”¨é¢„å®šä¹‰çš„æ˜ å°„è§„åˆ™ï¼Œé˜²æ­¢ç³»ç»Ÿèµ„æºï¼ˆå¦‚ CPU æ—¶é—´å’Œå†…å­˜ï¼‰è¢«è¿‡åº¦ä½¿ç”¨ã€‚è¿™ä¸€è¿‡ç¨‹é€šå¸¸åŒ…å«ä»¥ä¸‹æ­¥éª¤ï¼š

---

1.	 The administrator sets up a workload class, which outlines the quantity of sysÂ­tem resources that a group of applications can use, and a workload mapping, 
which details how to align an application workload with a workload class.

**ã€è¯‘æ–‡ã€‘** 1.	 ç®¡ç†å‘˜è®¾ç½®â€œå·¥ä½œè´Ÿè½½ç±»â€ï¼Œæ¦‚è¿°ä¸€ç»„åº”ç”¨ç¨‹åºå¯ä½¿ç”¨çš„ç³»ç»Ÿèµ„æºé‡ï¼›åŒæ—¶è®¾ç½®â€œå·¥ä½œè´Ÿè½½æ˜ å°„â€ï¼Œè¯¦è¿°å¦‚ä½•å°†åº”ç”¨ç¨‹åºçš„å·¥ä½œè´Ÿè½½ä¸å·¥ä½œè´Ÿè½½ç±»è¿›è¡Œå¯¹åº”ã€‚

---

2.	 When an application sends a request to the session layer of the ERPâ€™s database 
system, the relevant workload class is identified based on the session context 
information, such as the application name, application username, and database 
username.

**ã€è¯‘æ–‡ã€‘** 2.	 å½“åº”ç”¨ç¨‹åºå‘ ERP æ•°æ®åº“ç³»ç»Ÿçš„ä¼šè¯å±‚å‘é€è¯·æ±‚æ—¶ï¼Œç³»ç»Ÿä¼šæ ¹æ®ä¼šè¯ä¸Šä¸‹æ–‡ä¿¡æ¯ï¼ˆå¦‚åº”ç”¨ç¨‹åºåç§°ã€åº”ç”¨ç¨‹åºç”¨æˆ·åå’Œæ•°æ®åº“ç”¨æˆ·åï¼‰è¯†åˆ«å‡ºç›¸å…³çš„å·¥ä½œè´Ÿè½½ç±»ã€‚

---

3.	 Once the relevant workload class has been identified, the application request can 
have its resources managed according to the definition of the workload class.

**ã€è¯‘æ–‡ã€‘** 3.	 ä¸€æ—¦è¯†åˆ«å‡ºç›¸å…³çš„å·¥ä½œè´Ÿè½½ç±»ï¼Œåº”ç”¨ç¨‹åºè¯·æ±‚çš„èµ„æºå°±å¯ä»¥æ ¹æ®è¯¥å·¥ä½œè´Ÿè½½ç±»çš„å®šä¹‰è¿›è¡Œç®¡ç†ã€‚

---

The workload class should support at least three types of resource properties for 
regulation:
â€¢	 Statement thread limit: This represents the highest number of parallel threads 
that can execute a statement.
â€¢	 Statement memory limit: This represents the maximum memory allocation per 
statement.
â€¢	 Statement priority: This represents the priority level for a statement to be exeÂ­cuted in the job execution framework.

**ã€è¯‘æ–‡ã€‘** å·¥ä½œè´Ÿè½½ç±»åº”è‡³å°‘æ”¯æŒä»¥ä¸‹ä¸‰ç§èµ„æºå±æ€§ä»¥è¿›è¡Œè°ƒæ§ï¼š
â€¢	 è¯­å¥çº¿ç¨‹é™åˆ¶ï¼ˆStatement thread limitï¼‰ï¼šä»£è¡¨æ‰§è¡Œä¸€æ¡è¯­å¥å¯ä½¿ç”¨çš„æœ€å¤§å¹¶è¡Œçº¿ç¨‹æ•°ã€‚
â€¢	 è¯­å¥å†…å­˜é™åˆ¶ï¼ˆStatement memory limitï¼‰ï¼šä»£è¡¨æ¯æ¡è¯­å¥çš„æœ€å¤§å†…å­˜åˆ†é…é‡ã€‚
â€¢	 è¯­å¥ä¼˜å…ˆçº§ï¼ˆStatement priorityï¼‰ï¼šä»£è¡¨è¯­å¥åœ¨ä½œä¸šæ‰§è¡Œæ¡†æ¶ä¸­è¢«æ‰§è¡Œçš„ä¼˜å…ˆçº§ã€‚

---

15.2.2	  Side-by-Side Artificial Intelligence
The workload management looks different for side-by-side artificial intelligence 
using AI technology platform as it offers enhanced scalability features. Scalability 
is the degree to which a business process, component, or system can increase or 
decrease in size, volume, or the number of users it serves while still functioning 
correctly and predictably.

**ã€è¯‘æ–‡ã€‘** 15.2.2	 å¹¶è¡Œï¼ˆSide-by-Sideï¼‰äººå·¥æ™ºèƒ½
å¯¹äºä½¿ç”¨ AI æŠ€æœ¯å¹³å°çš„å¹¶è¡Œäººå·¥æ™ºèƒ½ï¼Œå·¥ä½œè´Ÿè½½ç®¡ç†æœ‰æ‰€ä¸åŒï¼Œå› ä¸ºå®ƒæä¾›äº†å¢å¼ºçš„å¯æ‰©å±•æ€§åŠŸèƒ½ã€‚å¯æ‰©å±•æ€§ï¼ˆScalabilityï¼‰æ˜¯æŒ‡ä¸šåŠ¡æµç¨‹ã€ç»„ä»¶æˆ–ç³»ç»Ÿåœ¨ä¿æŒæ­£ç¡®å’Œå¯é¢„æµ‹è¿è¡Œçš„åŒæ—¶ï¼Œå¢åŠ æˆ–å‡å°‘å…¶è§„æ¨¡ã€å®¹é‡æˆ–æœåŠ¡ç”¨æˆ·æ•°é‡çš„ç¨‹åº¦ã€‚

---

Essentially, scalability is about how a software applicaÂ­tionâ€™s resource usage changes predictably under varying system loads, such as an 
increase in multiuser or parallel load, while maintaining a reasonable response time.

**ã€è¯‘æ–‡ã€‘** æœ¬è´¨ä¸Šï¼Œå¯æ‰©å±•æ€§æ˜¯æŒ‡è½¯ä»¶åº”ç”¨ç¨‹åºçš„èµ„æºä½¿ç”¨æƒ…å†µå¦‚ä½•åœ¨ä¸åŒçš„ç³»ç»Ÿè´Ÿè½½ï¼ˆå¦‚å¤šç”¨æˆ·è´Ÿè½½æˆ–å¹¶è¡Œè´Ÿè½½å¢åŠ ï¼‰ä¸‹å‘ç”Ÿå¯é¢„æµ‹çš„å˜åŒ–ï¼ŒåŒæ—¶ä¿æŒåˆç†çš„å“åº”æ—¶é—´ã€‚

---

The AI technology platform typically offers a scalable infrastructure for inference 
and training, built on Kubernetes technology. We suggest utilizing this technology 
for workload management and performance of artificial intelligence scenarios.

**ã€è¯‘æ–‡ã€‘** AI æŠ€æœ¯å¹³å°é€šå¸¸åŸºäº Kubernetes æŠ€æœ¯ï¼Œä¸ºæ¨ç†å’Œè®­ç»ƒæä¾›å¯æ‰©å±•çš„åŸºç¡€è®¾æ–½ã€‚æˆ‘ä»¬å»ºè®®åˆ©ç”¨è¯¥æŠ€æœ¯è¿›è¡Œäººå·¥æ™ºèƒ½åœºæ™¯çš„å·¥ä½œè´Ÿè½½ç®¡ç†å’Œæ€§èƒ½ä¼˜åŒ–ã€‚

---

Kubernetes automates the processes of deploying, scaling, maintaining, scheduling, 
and operating multiple application containers across clusters of nodes. Containers 
operate on a shared operating system on host machines but are isolated from each 
other unless a user decides to connect them.

**ã€è¯‘æ–‡ã€‘** Kubernetes è‡ªåŠ¨åŒ–äº†è·¨èŠ‚ç‚¹é›†ç¾¤éƒ¨ç½²ã€æ‰©å±•ã€ç»´æŠ¤ã€è°ƒåº¦å’Œè¿è¡Œå¤šä¸ªåº”ç”¨ç¨‹åºå®¹å™¨ï¼ˆContainerï¼‰çš„è¿‡ç¨‹ã€‚å®¹å™¨åœ¨å®¿ä¸»æœºçš„å…±äº«æ“ä½œç³»ç»Ÿä¸Šè¿è¡Œï¼Œä½†å½¼æ­¤éš”ç¦»ï¼Œé™¤éç”¨æˆ·å†³å®šè¿æ¥å®ƒä»¬ã€‚

---

Kubernetes can be used with container 
runtimes and the container runtime interface. It includes tools for orchestration, 
secrets management, service discovery, scaling, and load balancing.

**ã€è¯‘æ–‡ã€‘** Kubernetes å¯ä¸å®¹å™¨è¿è¡Œæ—¶ï¼ˆContainer Runtimesï¼‰å’Œå®¹å™¨è¿è¡Œæ—¶æ¥å£é…åˆä½¿ç”¨ã€‚å®ƒåŒ…å«ç”¨äºç¼–æ’ã€å¯†é’¥ç®¡ç†ã€æœåŠ¡å‘ç°ã€æ‰©å±•å’Œè´Ÿè½½å‡è¡¡çš„å·¥å…·ã€‚

---

Kubernetes 
technology also includes automatic bin packing to optimally allocate resources for 
containers, and it applies configurations through configuration management feaÂ­tures. It safeguards container workloads by implementing or reversing changes and 
provides availability and quality checks for containers.

**ã€è¯‘æ–‡ã€‘** Kubernetes æŠ€æœ¯è¿˜åŒ…æ‹¬è‡ªåŠ¨è£…ç®±ï¼ˆBin packingï¼‰åŠŸèƒ½ï¼Œä»¥ä¼˜åŒ–åˆ†é…å®¹å™¨èµ„æºï¼Œå¹¶é€šè¿‡é…ç½®ç®¡ç†åŠŸèƒ½åº”ç”¨é…ç½®ã€‚å®ƒé€šè¿‡å®æ–½æˆ–å›æ»šæ›´æ”¹æ¥ä¿æŠ¤å®¹å™¨å·¥ä½œè´Ÿè½½ï¼Œå¹¶ä¸ºå®¹å™¨æä¾›å¯ç”¨æ€§å’Œè´¨é‡æ£€æŸ¥ã€‚

---

In Kubernetes, containers 
operate in pods, which are the basic scheduling unit for Kubernetes and add an 
abstraction layer to containers. Pods consist of one or more containers located on a 
host machine, and they can share resources.

**ã€è¯‘æ–‡ã€‘** åœ¨ Kubernetes ä¸­ï¼Œå®¹å™¨åœ¨ Pod ä¸­è¿è¡Œï¼ŒPod æ˜¯ Kubernetes çš„åŸºæœ¬è°ƒåº¦å•å…ƒï¼Œä¸ºå®¹å™¨å¢åŠ äº†ä¸€ä¸ªæŠ½è±¡å±‚ã€‚Pod ç”±ä½äºå®¿ä¸»æœºä¸Šçš„ä¸€ä¸ªæˆ–å¤šä¸ªå®¹å™¨ç»„æˆï¼Œå®ƒä»¬å¯ä»¥å…±äº«èµ„æºã€‚

---

Kubernetes identifies a machine with 
sufficient free compute capacity for a specific pod and launches the associated conÂ­tainers. To prevent conflicts, each pod is assigned a unique IP address, allowing 
applications to use ports.

**ã€è¯‘æ–‡ã€‘** Kubernetes ä¼šè¯†åˆ«å…·æœ‰è¶³å¤Ÿç©ºé—²è®¡ç®—èƒ½åŠ›æ¥è¿è¡Œç‰¹å®š Pod çš„æœºå™¨ï¼Œå¹¶å¯åŠ¨ç›¸å…³å®¹å™¨ã€‚ä¸ºé˜²æ­¢å†²çªï¼Œæ¯ä¸ª Pod åˆ†é…ä¸€ä¸ªå”¯ä¸€çš„ IP åœ°å€ï¼Œå…è®¸åº”ç”¨ç¨‹åºä½¿ç”¨ç«¯å£ã€‚

---

A node agent, known as a kubelet, manages the pods, their 
containers, and their images. A node, also referred to as a minion, is a worker 
machine in Kubernetes. It can be a physical machine or a virtual machine.

**ã€è¯‘æ–‡ã€‘** èŠ‚ç‚¹ä»£ç†ï¼ˆç§°ä¸º kubeletï¼‰è´Ÿè´£ç®¡ç† Podã€å…¶å®¹å™¨åŠå…¶é•œåƒã€‚èŠ‚ç‚¹ï¼ˆNodeï¼Œè¿‡å»ä¹Ÿç§°ä¸º Minionï¼‰æ˜¯ Kubernetes ä¸­çš„å·¥ä½œæœºå™¨ï¼Œå®ƒå¯ä»¥æ˜¯ç‰©ç†æœºæˆ–è™šæ‹Ÿæœºã€‚

---

Nodes 
contain the necessary services to run pods and receive management instructions 
from master components. Services found on nodes include Docker, kube-proxy, and 
kubelet.

**ã€è¯‘æ–‡ã€‘** èŠ‚ç‚¹åŒ…å«è¿è¡Œ Pod æ‰€éœ€çš„æœåŠ¡ï¼Œå¹¶ä»ä¸»ç»„ä»¶æ¥æ”¶ç®¡ç†æŒ‡ä»¤ã€‚èŠ‚ç‚¹ä¸Šçš„æœåŠ¡åŒ…æ‹¬ Dockerã€kube-proxy å’Œ kubeletã€‚

---

Tenant namespaces and content are respectively deployed and deleted as 
Helm releases. A release is an instance of a chart running in a Kubernetes cluster. 
One chart can often be installed many times in the same cluster.

**ã€è¯‘æ–‡ã€‘** ç§Ÿæˆ·å‘½åç©ºé—´å’Œå†…å®¹åˆ†åˆ«ä½œä¸º Helm å‘å¸ƒï¼ˆReleaseï¼‰è¿›è¡Œéƒ¨ç½²å’Œåˆ é™¤ã€‚å‘å¸ƒæ˜¯è¿è¡Œåœ¨ Kubernetes é›†ç¾¤ä¸­çš„ Chart å®ä¾‹ã€‚ä¸€ä¸ª Chart é€šå¸¸å¯ä»¥åœ¨åŒä¸€ä¸ªé›†ç¾¤ä¸­å®‰è£…å¤šæ¬¡ã€‚

---

The Helm tool 
installs charts into Kubernetes, creating a new release for each installation. The tenÂ­ant ID and related configuration are also easily injected by Helm.

**ã€è¯‘æ–‡ã€‘** Helm å·¥å…·å°† Chart å®‰è£…åˆ° Kubernetes ä¸­ï¼Œä¸ºæ¯æ¬¡å®‰è£…åˆ›å»ºä¸€ä¸ªæ–°çš„å‘å¸ƒã€‚ç§Ÿæˆ· ID å’Œç›¸å…³é…ç½®ä¹Ÿå¯ä»¥é€šè¿‡ Helm è½»æ¾æ³¨å…¥ã€‚

---

With the correct 
template logic, such as feature flags or a cloud provider, differences are managed. 
Upgrading tenants with new releases is also supported. Templating is also provided 
for creating Kubernetes job specifications. Additionally, the mounting of tenant data 
and access to GPUs are enabled.

**ã€è¯‘æ–‡ã€‘** é€šè¿‡æ­£ç¡®çš„æ¨¡æ¿é€»è¾‘ï¼ˆä¾‹å¦‚åŠŸèƒ½æ ‡è®°æˆ–äº‘æä¾›å•†é…ç½®ï¼‰ï¼Œå¯ä»¥ç®¡ç†ç¯å¢ƒå·®å¼‚ã€‚ç³»ç»Ÿä¹Ÿæ”¯æŒä½¿ç”¨æ–°å‘å¸ƒæ¥å‡çº§ç§Ÿæˆ·ï¼Œå¹¶æä¾›ç”¨äºåˆ›å»º Kubernetes ä½œä¸šè§„èŒƒçš„æ¨¡æ¿ã€‚æ­¤å¤–ï¼Œè¿˜æ”¯æŒç§Ÿæˆ·æ•°æ®çš„æŒ‚è½½å’Œ GPU çš„è®¿é—®ã€‚

---

Fig. 15.4â€‚ Performance improvement for inference calls
In addition, we recommend that within the ERP system, the outcomes of inferÂ­ences 
are stored by utilizing batch processing, thereby making these results readily accesÂ­sible for local use.

**ã€è¯‘æ–‡ã€‘** å›¾ 15.4 æ¨ç†è°ƒç”¨çš„æ€§èƒ½æå‡
æ­¤å¤–ï¼Œæˆ‘ä»¬å»ºè®®åœ¨ ERP ç³»ç»Ÿå†…ï¼Œåˆ©ç”¨æ‰¹å¤„ç†å­˜å‚¨æ¨ç†ï¼ˆInferenceï¼‰ç»“æœï¼Œä»è€Œä½¿è¿™äº›ç»“æœä¾¿äºæœ¬åœ°ç›´æ¥ä½¿ç”¨ã€‚

---

We also put forward the idea that specific types of side-by-side 
trained models should be imported into the ERP system and consumed locally. This 
approach would significantly enhance the speed of inference calls, given that local 
application programming interfaces (APIs) are typically 10 to 100 times faster than 
their remote counterparts.

**ã€è¯‘æ–‡ã€‘** æˆ‘ä»¬è¿˜æå‡ºï¼Œç‰¹å®šç±»å‹çš„å¹¶è¡Œè®­ç»ƒæ¨¡å‹åº”å¯¼å…¥ ERP ç³»ç»Ÿå¹¶åœ¨æœ¬åœ°ä½¿ç”¨ã€‚è¿™ç§æ–¹æ³•å°†æ˜¾è‘—æé«˜æ¨ç†è°ƒç”¨çš„é€Ÿåº¦ï¼Œå› ä¸ºæœ¬åœ°åº”ç”¨ç¨‹åºç¼–ç¨‹æ¥å£ï¼ˆAPIï¼‰é€šå¸¸æ¯”è¿œç¨‹ API å¿« 10 åˆ° 100 å€ã€‚

---

A technology that aids in the export and import of models 
is the Open Neural Network Exchange (ONNX). For both deep learning models and 
traditional models of machine-based intelligence, ONNX provides an open-source 
format.

**ã€è¯‘æ–‡ã€‘** å¼€æ”¾ç¥ç»ç½‘ç»œäº¤æ¢ï¼ˆONNXï¼‰æ˜¯ä¸€ç§æœ‰åŠ©äºæ¨¡å‹å¯¼å‡ºå’Œå¯¼å…¥çš„æŠ€æœ¯ã€‚å¯¹äºæ·±åº¦å­¦ä¹ æ¨¡å‹å’Œä¼ ç»Ÿçš„æœºå™¨æ™ºèƒ½æ¨¡å‹ï¼ŒONNX æä¾›äº†ä¸€ç§å¼€æºæ ¼å¼ã€‚

---

It also establishes built-in operators and common data types, along with a 
computation graph model that can be expanded. There are a multitude of hardware, 
software, and frameworks that support ONNX.

**ã€è¯‘æ–‡ã€‘** å®ƒè¿˜å»ºç«‹äº†å†…ç½®è¿ç®—ç¬¦å’Œé€šç”¨æ•°æ®ç±»å‹ï¼Œä»¥åŠå¯æ‰©å±•çš„è®¡ç®—å›¾æ¨¡å‹ã€‚ç›®å‰æœ‰å¤šç§ç¡¬ä»¶ã€è½¯ä»¶å’Œæ¡†æ¶æ”¯æŒ ONNXã€‚

---

The transition from research to proÂ­duction can be made more efficient and compatible across different frameworks, 
thereby fostering innovation in the field of machine-based intelligence.

**ã€è¯‘æ–‡ã€‘** è¿™ä½¿å¾—ä»ç ”ç©¶åˆ°ç”Ÿäº§çš„è¿‡æ¸¡å¯ä»¥åœ¨ä¸åŒæ¡†æ¶ä¹‹é—´å˜å¾—æ›´åŠ é«˜æ•ˆå’Œå…¼å®¹ï¼Œä»è€Œä¿ƒè¿›æœºå™¨æ™ºèƒ½é¢†åŸŸçš„åˆ›æ–°ã€‚

---

15.2.3	  Performance-Optimized Programming
From our viewpoint, the primary factor in optimizing the performance of an ERP 
system lies in the programming. Various implementation methods can be discovÂ­ered under the term Performance-Optimized Programming.

**ã€è¯‘æ–‡ã€‘** 15.2.3	 æ€§èƒ½ä¼˜åŒ–ç¼–ç¨‹
åœ¨æˆ‘ä»¬çœ‹æ¥ï¼Œä¼˜åŒ– ERP ç³»ç»Ÿæ€§èƒ½çš„ä¸»è¦å› ç´ åœ¨äºç¼–ç¨‹ã€‚åœ¨â€œæ€§èƒ½ä¼˜åŒ–ç¼–ç¨‹â€è¿™ä¸€æœ¯è¯­ä¸‹ï¼ŒåŒ…å«å¤šç§å®ç°æ–¹æ³•ã€‚

---

In relation to network 
and data, the following KPIs can be defined:
â€¢	 Count of network roundtrips for each user interaction step: The duration of a 
roundtrip is contingent on the number of network hops, essentially the count of 
intermediary devices that data must traverse from source to destination, and 
latency, which is the time it takes for a packet to be sent from the source and 
received at the destination.

**ã€è¯‘æ–‡ã€‘** å…³äºç½‘ç»œå’Œæ•°æ®ï¼Œå¯ä»¥å®šä¹‰ä»¥ä¸‹å…³é”®ç»©æ•ˆæŒ‡æ ‡ï¼ˆKPIï¼‰ï¼š
â€¢	 æ¯ä¸ªç”¨æˆ·äº¤äº’æ­¥éª¤çš„ç½‘ç»œå¾€è¿”æ¬¡æ•°ï¼šå¾€è¿”çš„æŒç»­æ—¶é—´å–å†³äºç½‘ç»œè·³æ•°ï¼ˆå³æ•°æ®ä»æºåˆ°ç›®çš„åœ°å¿…é¡»ç»è¿‡çš„ä¸­é—´è®¾å¤‡çš„æ•°é‡ï¼‰å’Œå»¶è¿Ÿï¼ˆå³æ•°æ®åŒ…ä»æºå‘é€åˆ°ç›®çš„åœ°æ¥æ”¶æ‰€éœ€çš„æ—¶é—´ï¼‰ã€‚

---

When data is transmitted over wide area networks 
(WAN) or global area networks (GAN), latency makes up the majority of the

**ã€è¯‘æ–‡ã€‘** å½“æ•°æ®é€šè¿‡å¹¿åŸŸç½‘ï¼ˆWANï¼‰æˆ–å…¨çƒå±€åŸŸç½‘ï¼ˆGANï¼‰ä¼ è¾“æ—¶ï¼Œå»¶è¿Ÿå æ®äº†å¾€è¿”æ—¶é—´çš„å¤§éƒ¨åˆ†ã€‚

---

