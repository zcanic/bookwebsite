# Embedding Artificial Intelligence into ERP Software A Conceptual View on Business AI with Examples from SAP S4HANA (Siar Sarferaz) (z-library.sk, 1lib.sk, z-lib.sk) - ç¬¬106éƒ¨åˆ†

**åŸå§‹é¡µç **: 316 - 318
**æ®µè½æ•°é‡**: 12
**ç¿»è¯‘å·¥å…·**: Claude Code CLI

## ğŸ“– ç¿»è¯‘ç­–ç•¥å’Œä¸Šä¸‹æ–‡ä¿¡æ¯

- **ä½¿ç”¨çš„ç¿»è¯‘ç­–ç•¥**: å®Œæ•´ä¸Šä¸‹æ–‡
- **å‰æ–‡ä¸Šä¸‹æ–‡é¡µç **: 315-315 (850 å­—ç¬¦)
- **åæ–‡ä¸Šä¸‹æ–‡é¡µç **: 319-319 (538 å­—ç¬¦)

*æ³¨ï¼šç¿»è¯‘æ—¶å·²ä½¿ç”¨"å®Œæ•´ä¸Šä¸‹æ–‡"ç­–ç•¥ï¼Œå‚è€ƒå‰åæ–‡ä¸Šä¸‹æ–‡ä»¥ç¡®ä¿æœ¯è¯­ä¸€è‡´æ€§å’Œå†…å®¹è¿è´¯æ€§*

**æœ¯è¯­è¯´æ˜**: Operator è¯‘ä¸ºâ€œç®—å­â€ï¼Œæ˜¯ SAP Data Intelligence ä¸­çš„æ ‡å‡†æœ¯è¯­ï¼›Artifact è¯‘ä¸ºâ€œåˆ¶å“â€ï¼›Blob ä¿ç•™åŸæ–‡ï¼ŒæŒ‡äºŒè¿›åˆ¶å¤§å¯¹è±¡ï¼›Side-by-Side è¯‘ä¸ºâ€œå¹¶è¡Œâ€ï¼ŒæŒ‡ ERP ç³»ç»Ÿä¸å…¶æ‰©å±•åº”ç”¨çš„ä¸€ç§æ¶æ„å…³ç³»ã€‚

---

pipelines, ISLM assumes the [ISLM_TRAINING_PIPELINE] string to be included as part of the description. This might be replaced in future versions with an explicit flag.

**ã€è¯‘æ–‡ã€‘** ä¸ºäº†è¯†åˆ«è¿™äº›ç®¡é“ï¼ŒISLM å‡å®šæè¿°ä¸­åŒ…å« [ISLM_TRAINING_PIPELINE] å­—ç¬¦ä¸²ã€‚åœ¨æœªæ¥çš„ç‰ˆæœ¬ä¸­ï¼Œè¿™å¯èƒ½ä¼šè¢«æ˜ç¡®çš„æ ‡å¿—æ‰€å–ä»£ã€‚

---

1. Workflow Trigger
The operator triggers the execution of the pipeline.

**ã€è¯‘æ–‡ã€‘** 1. å·¥ä½œæµè§¦å‘å™¨ (Workflow Trigger)
è¯¥ç®—å­ç”¨äºè§¦å‘ç®¡é“çš„æ‰§è¡Œã€‚

---

2. Cloud Data Integration

**ã€è¯‘æ–‡ã€‘** 2. äº‘æ•°æ®é›†æˆ (Cloud Data Integration)

---

3. Flowagent CSV Prodâ€¦
The operator transforms the application into a CSV file.

**ã€è¯‘æ–‡ã€‘** 3. Flowagent CSV ç”Ÿæˆå™¨ (Flowagent CSV Producer)
è¯¥ç®—å­å°†åº”ç”¨ç¨‹åºæ•°æ®è½¬æ¢ä¸º CSV æ–‡ä»¶ã€‚

---

4. Algorithm
The operator trains the artificial intelligence algorithm based on the application data. This operator is coded in Python.

**ã€è¯‘æ–‡ã€‘** 4. ç®—æ³• (Algorithm)
è¯¥ç®—å­åŸºäºåº”ç”¨æ•°æ®è®­ç»ƒäººå·¥æ™ºèƒ½ç®—æ³•ã€‚æ­¤ç®—å­æ˜¯ç”¨ Python ç¼–å†™çš„ã€‚

---

5. Artifact Producer
The operator stores the trained model.

**ã€è¯‘æ–‡ã€‘** 5. åˆ¶å“ç”Ÿæˆå™¨ (Artifact Producer)
è¯¥ç®—å­ç”¨äºå­˜å‚¨è®­ç»ƒå¥½çš„æ¨¡å‹ã€‚

---

6. Submit Metrics
The operator processes metrics for model accuracy.

**ã€è¯‘æ–‡ã€‘** 6. æäº¤æŒ‡æ ‡ (Submit Metrics)
è¯¥ç®—å­å¤„ç†æ¨¡å‹å‡†ç¡®æ€§çš„ç›¸å…³æŒ‡æ ‡ã€‚

---

7. Graph Terminator
The operator terminates the pipeline and releases the used system resources.

**ã€è¯‘æ–‡ã€‘** 7. å›¾ç»ˆæ­¢å™¨ (Graph Terminator)
è¯¥ç®—å­ç»ˆæ­¢ç®¡é“è¿è¡Œå¹¶é‡Šæ”¾æ‰€å ç”¨çš„ç³»ç»Ÿèµ„æºã€‚

---

20.3 Implementing Side-by-Side AI Applications

**ã€è¯‘æ–‡ã€‘** 20.3 å®æ–½å¹¶è¡Œ AI åº”ç”¨

---

transferred to the structure, which is required by the operator. The input port of the operator receives the application data with which the Scikit-Learn linear regression algorithm is trained. Model metrics and the blob ID of the trained model are exposed by output ports of the operator.

**ã€è¯‘æ–‡ã€‘** æ•°æ®è¢«ä¼ è¾“åˆ°ç®—å­æ‰€éœ€çš„ç»“æ„ä¸­ã€‚ç®—å­çš„è¾“å…¥ç«¯å£æ¥æ”¶åº”ç”¨æ•°æ®ï¼Œç”¨äºè®­ç»ƒ Scikit-Learn çº¿æ€§å›å½’ç®—æ³•ã€‚æ¨¡å‹æŒ‡æ ‡å’Œè®­ç»ƒåæ¨¡å‹çš„ Blob ID é€šè¿‡ç®—å­çš„è¾“å‡ºç«¯å£æš´éœ²å‡ºæ¥ã€‚

---

Listing 20.5 Coding for Operator Responsible for Model Training

**ã€è¯‘æ–‡ã€‘** æ¸…å• 20.5 è´Ÿè´£æ¨¡å‹è®­ç»ƒçš„ç®—å­ä»£ç 

---

# Python script to perform training on input data & generate Metrics & Model Blob
def on_input(data):
# Step 1: Import libraries
import pandas as pd
import io
import numpy as np
import logging
logging.basicConfig(level=logging.DEBUG, format='%(asctime)s - %(levelname)s - %(message)s')
api.logger.info("Your message")
# Step 2: Read data and display it
dataset = pd.read_csv(io.StringIO(data), sep=",")
x = dataset['OrderQuantity'].values.reshape(-1,1)
y = dataset['TargetQuantity'].values.reshape(-1,1)
# Step 3: Apply linear regression for model training
from sklearn.linear_model import LinearRegression
lm = LinearRegression()
lm.fit(x, y)
# Step 4: Calculate metrics and predict
intercept = lm.intercept_
slope = lm.coef_
metrics_dict = {"Intercept: " , str(intercept[0]), "Slope: ", str(slope[0,0])}
api.send("metrics", api.Message(metrics_dict))
# Step 5: Store the model for future inference
import pickle
model_blob = pickle.dumps(lm)
api.send("modelBlob", model_blob)
api.set_port_callback("input", on_input)

**ã€è¯‘æ–‡ã€‘** # ç”¨äºå¯¹è¾“å…¥æ•°æ®æ‰§è¡Œè®­ç»ƒå¹¶ç”ŸæˆæŒ‡æ ‡å’Œæ¨¡å‹ Blob çš„ Python è„šæœ¬
def on_input(data):
# æ­¥éª¤ 1ï¼šå¯¼å…¥åº“
import pandas as pd
import io
import numpy as np
import logging
logging.basicConfig(level=logging.DEBUG, format='%(asctime)s - %(levelname)s - %(message)s')
api.logger.info("Your message")
# æ­¥éª¤ 2ï¼šè¯»å–å¹¶æ˜¾ç¤ºæ•°æ®
dataset = pd.read_csv(io.StringIO(data), sep=",")
x = dataset['OrderQuantity'].values.reshape(-1,1)
y = dataset['TargetQuantity'].values.reshape(-1,1)
# æ­¥éª¤ 3ï¼šåº”ç”¨çº¿æ€§å›å½’è¿›è¡Œæ¨¡å‹è®­ç»ƒ
from sklearn.linear_model import LinearRegression
lm = LinearRegression()
lm.fit(x, y)
# æ­¥éª¤ 4ï¼šè®¡ç®—æŒ‡æ ‡å¹¶é¢„æµ‹
intercept = lm.intercept_
slope = lm.coef_
metrics_dict = {"Intercept: " , str(intercept[0]), "Slope: ", str(slope[0,0])}
api.send("metrics", api.Message(metrics_dict))
# æ­¥éª¤ 5ï¼šå­˜å‚¨æ¨¡å‹ä»¥ä¾›åç»­æ¨ç†ä½¿ç”¨
import pickle
model_blob = pickle.dumps(lm)
api.send("modelBlob", model_blob)
api.set_port_callback("input", on_input)

---

