# Embedding Artificial Intelligence into ERP Software A Conceptual View on Business AI with Examples from SAP S4HANA (Siar Sarferaz) (z-library.sk, 1lib.sk, z-lib.sk) - ç¬¬140éƒ¨åˆ†

**åŸå§‹é¡µç **: 418 - 420
**æ®µè½æ•°é‡**: 34
**ç¿»è¯‘å·¥å…·**: Claude Code CLI

## ğŸ“– ç¿»è¯‘ç­–ç•¥å’Œä¸Šä¸‹æ–‡ä¿¡æ¯

- **ä½¿ç”¨çš„ç¿»è¯‘ç­–ç•¥**: å®Œæ•´ä¸Šä¸‹æ–‡
- **å‰æ–‡ä¸Šä¸‹æ–‡é¡µç **: 417-417 (3086 å­—ç¬¦)
- **åæ–‡ä¸Šä¸‹æ–‡é¡µç **: 421-421 (2626 å­—ç¬¦)

*æ³¨ï¼šç¿»è¯‘æ—¶å·²ä½¿ç”¨"å®Œæ•´ä¸Šä¸‹æ–‡"ç­–ç•¥ï¼Œå‚è€ƒå‰åæ–‡ä¸Šä¸‹æ–‡ä»¥ç¡®ä¿æœ¯è¯­ä¸€è‡´æ€§å’Œå†…å®¹è¿è´¯æ€§*

**æœ¯è¯­è¯´æ˜**: 1. Data subject: è¯‘ä¸ºâ€œæ•°æ®ä¸»ä½“â€ï¼ŒæŒ‡ä¸ªäººæ•°æ®æ‰€æŒ‡å‘çš„è‡ªç„¶äººï¼Œæ˜¯GDPRç­‰æ³•è§„ä¸­çš„æ ‡å‡†æœ¯è¯­ã€‚ 2. Profiling: è¯‘ä¸ºâ€œç”»åƒåˆ†æâ€æˆ–â€œç”»åƒâ€ï¼ŒæŒ‡è‡ªåŠ¨å¤„ç†ä¸ªäººæ•°æ®ä»¥è¯„ä¼°ä¸ªäººç‰¹å¾ã€‚ 3. Black box: è¯‘ä¸ºâ€œé»‘ç›’â€ï¼ŒæŒ‡å†…éƒ¨è¿ä½œä¸é€æ˜çš„ç®—æ³•æˆ–ç³»ç»Ÿã€‚ 4. Red lines: è¯‘ä¸ºâ€œçº¢çº¿â€ï¼Œæ„æŒ‡ä¸å¯é€¾è¶Šçš„é“å¾·æˆ–æ³•å¾‹ç•Œé™ã€‚ 5. Confidence level: è¯‘ä¸ºâ€œç½®ä¿¡åº¦â€ï¼Œç»Ÿè®¡å­¦å’ŒAIé¢†åŸŸé€šç”¨æœ¯è¯­ã€‚

---

â€¢	 To enable transparency and traceability, the data sets and procedures utilized to generate an artificial intelligence systemâ€™s judgment, including those for data collection and data labeling as well as the algorithms employed by the created artificial intelligence business applications, must be recorded.

**ã€è¯‘æ–‡ã€‘** â€¢	 ä¸ºäº†å®ç°é€æ˜åº¦å’Œå¯è¿½æº¯æ€§ï¼Œå¿…é¡»è®°å½•ç”¨äºç”Ÿæˆäººå·¥æ™ºèƒ½ç³»ç»Ÿåˆ¤æ–­çš„æ•°æ®é›†å’Œç¨‹åºï¼ˆåŒ…æ‹¬æ•°æ®æ”¶é›†å’Œæ•°æ®æ ‡æ³¨ç¨‹åºï¼‰ï¼Œä»¥åŠå·²æ„å»ºçš„äººå·¥æ™ºèƒ½å•†ä¸šåº”ç”¨æ‰€ä½¿ç”¨çš„ç®—æ³•ã€‚

---

â€¢	 As part of the development process, the capabilities and constraints must be described in a way that is acceptable for the current use case. This must provide details on the artificial intelligence systemâ€™s accuracy level (performance metric), as well as its capabilities and restrictions.

**ã€è¯‘æ–‡ã€‘** â€¢	 ä½œä¸ºå¼€å‘è¿‡ç¨‹çš„ä¸€éƒ¨åˆ†ï¼Œå¿…é¡»ä»¥é€‚åˆå½“å‰ç”¨ä¾‹çš„æ–¹å¼æè¿°ç³»ç»Ÿçš„èƒ½åŠ›å’Œé™åˆ¶ã€‚è¿™å¿…é¡»åŒ…å«å…³äºäººå·¥æ™ºèƒ½ç³»ç»Ÿå‡†ç¡®åº¦æ°´å¹³ï¼ˆæ€§èƒ½æŒ‡æ ‡ï¼‰åŠå…¶èƒ½åŠ›å’Œå±€é™æ€§çš„è¯¦ç»†ä¿¡æ¯ã€‚

---

â€¢	 If the data subject requests it, products that use artificial intelligence business applications in the processing of personal data shall, in accordance with data privacy and protection policy, offer as much transparency as possible regarding how the artificial intelligence was used in plain and straightforward language.

**ã€è¯‘æ–‡ã€‘** â€¢	 å¦‚æœæ•°æ®ä¸»ä½“æå‡ºè¯·æ±‚ï¼Œåœ¨å¤„ç†ä¸ªäººæ•°æ®æ—¶ä½¿ç”¨äººå·¥æ™ºèƒ½å•†ä¸šåº”ç”¨çš„äº§å“ï¼Œåº”ä¾æ®æ•°æ®éšç§å’Œä¿æŠ¤æ”¿ç­–ï¼Œç”¨é€šä¿—æ˜“æ‡‚çš„è¯­è¨€å°½å¯èƒ½é€æ˜åœ°æä¾›å…³äºå¦‚ä½•ä½¿ç”¨äººå·¥æ™ºèƒ½çš„ä¿¡æ¯ã€‚

---

â€¢	 In accordance and compliance with data privacy and protection policy, artificial intelligence software that use automated decision-making or profiling must be able to, upon request from the data subject, provide explanations that, to the extent possible, explain the data segment the subject was placed into and the reasons they were placed there. In addition, if the data subject asks for them, the decisionâ€™s justifications must be disclosed. The justification must give the data subject justification for contesting the judgment.

**ã€è¯‘æ–‡ã€‘** â€¢	 æ ¹æ®å¹¶éµå®ˆæ•°æ®éšç§å’Œä¿æŠ¤æ”¿ç­–ï¼Œä½¿ç”¨è‡ªåŠ¨åŒ–å†³ç­–æˆ–ç”»åƒåˆ†æï¼ˆprofilingï¼‰çš„äººå·¥æ™ºèƒ½è½¯ä»¶å¿…é¡»èƒ½å¤Ÿåœ¨æ•°æ®ä¸»ä½“æå‡ºè¯·æ±‚æ—¶ï¼Œå°½å¯èƒ½è§£é‡Šè¯¥ä¸»ä½“è¢«å½’å…¥çš„æ•°æ®åˆ†ç¾¤ï¼ˆdata segmentï¼‰ä»¥åŠå½’å…¥è¯¥ç¾¤ä½“çš„ç†ç”±ã€‚æ­¤å¤–ï¼Œå¦‚æœæ•°æ®ä¸»ä½“è¦æ±‚ï¼Œå¿…é¡»æŠ«éœ²å†³ç­–çš„ç†ç”±ã€‚è¯¥ç†ç”±å¿…é¡»ä¸ºæ•°æ®ä¸»ä½“æä¾›è´¨ç–‘è¯¥åˆ¤æ–­çš„ä¾æ®ã€‚

---

â€¢	 The methodologies used for creating, analyzing, and validating the artificial intelligence business applications, as well as the results or decisions it makes, must all be completely documented as part of the development process.

**ã€è¯‘æ–‡ã€‘** â€¢	 ç”¨äºåˆ›å»ºã€åˆ†æå’ŒéªŒè¯äººå·¥æ™ºèƒ½å•†ä¸šåº”ç”¨çš„æ–¹æ³•è®ºï¼Œä»¥åŠå®ƒäº§ç”Ÿçš„ç»“æœæˆ–å†³ç­–ï¼Œéƒ½å¿…é¡»ä½œä¸ºå¼€å‘è¿‡ç¨‹çš„ä¸€éƒ¨åˆ†è¿›è¡Œå®Œæ•´çš„è®°å½•ã€‚

---

â€¢	 Where appropriate, when communicating directly with people (including through â€œChatbotsâ€ or Conversational AI):

**ã€è¯‘æ–‡ã€‘** â€¢	 åœ¨é€‚å½“çš„æƒ…å†µä¸‹ï¼Œå½“ç›´æ¥ä¸äººæ²Ÿé€šæ—¶ï¼ˆåŒ…æ‹¬é€šè¿‡â€œèŠå¤©æœºå™¨äººâ€æˆ–å¯¹è¯å¼AIï¼‰ï¼š

---

â€“â€“ Artificial intelligence business applications must be identified to the proper end users as such.

**ã€è¯‘æ–‡ã€‘** â€“â€“ å¿…é¡»å‘ç›¸å…³çš„æœ€ç»ˆç”¨æˆ·è¡¨æ˜äººå·¥æ™ºèƒ½å•†ä¸šåº”ç”¨çš„èº«ä»½ã€‚

---

â€“â€“ Where applicable and practical, a choice must be given to allow a user to choose human interaction over engaging with an artificial intelligence system.

**ã€è¯‘æ–‡ã€‘** â€“â€“ åœ¨é€‚ç”¨ä¸”å¯è¡Œçš„æƒ…å†µä¸‹ï¼Œå¿…é¡»æä¾›é€‰é¡¹ï¼Œå…è®¸ç”¨æˆ·é€‰æ‹©ä¸äººäº’åŠ¨è€Œä¸æ˜¯ä¸äººå·¥æ™ºèƒ½ç³»ç»Ÿäº’åŠ¨ã€‚

---

â€“â€“ Artificial intelligence systems must be created in a way that discourages people from feeling empathy or attachment for the artificial intelligence software.

**ã€è¯‘æ–‡ã€‘** â€“â€“ äººå·¥æ™ºèƒ½ç³»ç»Ÿçš„åˆ›å»ºæ–¹å¼å¿…é¡»èƒ½å¤Ÿé¿å…äººä»¬å¯¹äººå·¥æ™ºèƒ½è½¯ä»¶äº§ç”Ÿç§»æƒ…æˆ–ä¾æ‹ã€‚

---

â€“â€“ Users of artificial intelligence systems must be clearly informed that social interaction is simulated.

**ã€è¯‘æ–‡ã€‘** â€“â€“ å¿…é¡»æ˜ç¡®å‘ŠçŸ¥äººå·¥æ™ºèƒ½ç³»ç»Ÿçš„ç”¨æˆ·ï¼Œè¿™ç§ç¤¾äº¤äº’åŠ¨æ˜¯æ¨¡æ‹Ÿçš„ã€‚

---

â€¢	 Based on the use case, artificial intelligence system developers shall make every effort to ensure that the decisions, recommendations, and outputs of the artificial intelligence system are as visible as feasible. The user interface (UI) or application logs can be used for this to enable the best understanding and traceability of these.

**ã€è¯‘æ–‡ã€‘** â€¢	 åŸºäºç”¨ä¾‹ï¼Œäººå·¥æ™ºèƒ½ç³»ç»Ÿå¼€å‘äººå‘˜åº”å°½ä¸€åˆ‡åŠªåŠ›ç¡®ä¿äººå·¥æ™ºèƒ½ç³»ç»Ÿçš„å†³ç­–ã€å»ºè®®å’Œè¾“å‡ºå°½å¯èƒ½å¯è§ã€‚å¯ä»¥åˆ©ç”¨ç”¨æˆ·ç•Œé¢ï¼ˆUIï¼‰æˆ–åº”ç”¨ç¨‹åºæ—¥å¿—æ¥å®ç°è¿™ä¸€ç‚¹ï¼Œä»¥å®ç°å¯¹è¿™äº›å†…å®¹çš„æœ€ä½³ç†è§£å’Œå¯è¿½æº¯æ€§ã€‚

---

â€¢	 The user must be informed that confidence levels are commonly used by artificial intelligence systems, and if necessary, the user must be provided with the actual confidence level of a given output.

**ã€è¯‘æ–‡ã€‘** â€¢	 å¿…é¡»å‘ŠçŸ¥ç”¨æˆ·äººå·¥æ™ºèƒ½ç³»ç»Ÿé€šå¸¸ä½¿ç”¨ç½®ä¿¡åº¦ï¼ˆconfidence levelsï¼‰ï¼Œå¹¶ä¸”å¦‚æœ‰å¿…è¦ï¼Œå¿…é¡»å‘ç”¨æˆ·æä¾›ç‰¹å®šè¾“å‡ºçš„å®é™…ç½®ä¿¡åº¦ã€‚

---

â€¢	 The goal, limitations, requirements, and judgments of the artificial intelligence system must be specified and documented in a way that is transparent to the non-technical general reader or user.

**ã€è¯‘æ–‡ã€‘** â€¢	 äººå·¥æ™ºèƒ½ç³»ç»Ÿçš„ç›®æ ‡ã€é™åˆ¶ã€è¦æ±‚å’Œåˆ¤æ–­å¿…é¡»ä»¥å¯¹éæŠ€æœ¯èƒŒæ™¯çš„æ™®é€šè¯»è€…æˆ–ç”¨æˆ·é€æ˜çš„æ–¹å¼è¿›è¡Œå…·ä½“è¯´æ˜å’Œè®°å½•ã€‚

---

â€¢	 Software/conditions involving black boxes and/or deep neural networks:

**ã€è¯‘æ–‡ã€‘** â€¢	 æ¶‰åŠé»‘ç›’å’Œ/æˆ–æ·±åº¦ç¥ç»ç½‘ç»œçš„è½¯ä»¶/æ¡ä»¶ï¼š

---

â€“â€“ Where developers has created so-called black box algorithms, further explicability measures must be offered. Traceability, auditability, and open documentation and disclosure of the softwareâ€™s capabilities should be among them.

**ã€è¯‘æ–‡ã€‘** â€“â€“ å½“å¼€å‘äººå‘˜åˆ›å»ºäº†æ‰€è°“çš„é»‘ç›’ç®—æ³•æ—¶ï¼Œå¿…é¡»æä¾›è¿›ä¸€æ­¥çš„å¯è§£é‡Šæ€§æªæ–½ã€‚è¿™åº”åŒ…æ‹¬å¯è¿½æº¯æ€§ã€å¯å®¡è®¡æ€§ä»¥åŠå¯¹è½¯ä»¶èƒ½åŠ›çš„å…¬å¼€è®°å½•å’ŒæŠ«éœ²ã€‚

---

â€“â€“ An explanation of the output must be made available wherever possible; if this is not practicable, users must be informed that the output might not be completely comprehensible.

**ã€è¯‘æ–‡ã€‘** â€“â€“ å¿…é¡»å°½å¯èƒ½æä¾›å¯¹è¾“å‡ºçš„è§£é‡Šï¼›å¦‚æœä¸å¯è¡Œï¼Œå¿…é¡»å‘ŠçŸ¥ç”¨æˆ·è¯¥è¾“å‡ºå¯èƒ½æ— æ³•è¢«å®Œå…¨ç†è§£ã€‚

---

â€“â€“ The need for this information will depend on the circumstances and the gravity of the repercussions.

**ã€è¯‘æ–‡ã€‘** â€“â€“ å¯¹æ­¤ç±»ä¿¡æ¯çš„éœ€æ±‚å°†å–å†³äºå…·ä½“æƒ…å†µå’Œåæœçš„ä¸¥é‡ç¨‹åº¦ã€‚

---

â€¢	 The context and setting in which an artificial intelligence system will work must be considered during development so that, despite the best of intentions, humans are not likely to suffer harm as a result of the deployment of artificial intelligence systems.

**ã€è¯‘æ–‡ã€‘** â€¢	 åœ¨å¼€å‘è¿‡ç¨‹ä¸­å¿…é¡»è€ƒè™‘äººå·¥æ™ºèƒ½ç³»ç»Ÿå·¥ä½œçš„èƒŒæ™¯å’Œç¯å¢ƒï¼Œä»¥ç¡®ä¿å³ä½¿å‡ºäºå¥½æ„ï¼Œäººç±»ä¹Ÿä¸ä¼šå› äººå·¥æ™ºèƒ½ç³»ç»Ÿçš„éƒ¨ç½²è€Œå—åˆ°ä¼¤å®³ã€‚

---

â€¢	 This policy shall apply to the complete software solution to the degree that a third-party artificial intelligence system (e.g., TensorFlow) is embedded in the solutions.

**ã€è¯‘æ–‡ã€‘** â€¢	 æœ¬æ”¿ç­–é€‚ç”¨äºå®Œæ•´çš„è½¯ä»¶è§£å†³æ–¹æ¡ˆï¼Œå…¶é€‚ç”¨èŒƒå›´æ¶µç›–è¯¥è§£å†³æ–¹æ¡ˆä¸­åµŒå…¥çš„ç¬¬ä¸‰æ–¹äººå·¥æ™ºèƒ½ç³»ç»Ÿï¼ˆä¾‹å¦‚ TensorFlowï¼‰çš„ç¨‹åº¦ã€‚

---

25.2.4	  Civic Society

**ã€è¯‘æ–‡ã€‘** 25.2.4 å…¬æ°‘ç¤¾ä¼š

---

Artificial intelligence business applications must be designed to enhance, complement, and empower human cognitive, social, and cultural abilities rather than to prevent or limit behaviors appropriate for a free society. As it relates to civic society, teams should take the following into account when designing or implementing artificial intelligence systems:

**ã€è¯‘æ–‡ã€‘** äººå·¥æ™ºèƒ½å•†ä¸šåº”ç”¨çš„è®¾è®¡å¿…é¡»æ—¨åœ¨å¢å¼ºã€è¡¥å……å’Œèµ‹èƒ½äººç±»çš„è®¤çŸ¥ã€ç¤¾ä¼šå’Œæ–‡åŒ–èƒ½åŠ›ï¼Œè€Œä¸æ˜¯é˜»æ­¢æˆ–é™åˆ¶é€‚åˆè‡ªç”±ç¤¾ä¼šçš„è¡Œä¸ºã€‚å…³äºå…¬æ°‘ç¤¾ä¼šï¼Œå›¢é˜Ÿåœ¨è®¾è®¡æˆ–å®æ–½äººå·¥æ™ºèƒ½ç³»ç»Ÿæ—¶åº”è€ƒè™‘ä»¥ä¸‹å‡ ç‚¹ï¼š

---

â€¢	 Artificial intelligence systems cannot be created or implemented for human surveillance that uses biometrics, facial recognition, or other distinguishing characteristics to target specific people or groups with the intention of violating their human rights.

**ã€è¯‘æ–‡ã€‘** â€¢	 äººå·¥æ™ºèƒ½ç³»ç»Ÿçš„åˆ›å»ºæˆ–å®æ–½ä¸èƒ½ç”¨äºåˆ©ç”¨ç”Ÿç‰©è¯†åˆ«ã€é¢éƒ¨è¯†åˆ«æˆ–å…¶ä»–æ˜¾è‘—ç‰¹å¾è¿›è¡Œäººç±»ç›‘æ§ï¼Œä»¥é’ˆå¯¹ç‰¹å®šäººç¾¤æˆ–ç¾¤ä½“å¹¶æ„å›¾ä¾µçŠ¯å…¶äººæƒã€‚

---

â€¢	 Artificial intelligence systems must not be created or used for activities that discriminate against or exclude certain individuals or groups from opportunities and advantages that artificial intelligence may bring to the general public.

**ã€è¯‘æ–‡ã€‘** â€¢	 äººå·¥æ™ºèƒ½ç³»ç»Ÿçš„åˆ›å»ºæˆ–ä½¿ç”¨ä¸å¾—ç”¨äºæ­§è§†æˆ–å°†ç‰¹å®šä¸ªäººæˆ–ç¾¤ä½“æ’é™¤åœ¨äººå·¥æ™ºèƒ½å¯èƒ½ç»™å…¬ä¼—å¸¦æ¥çš„æœºä¼šå’Œä¼˜åŠ¿ä¹‹å¤–çš„æ´»åŠ¨ã€‚

---

â€¢	 Artificial intelligence systems may not be created or used to unfairly manipulate people or groups in public spaces or the media or for other similar purposes.

**ã€è¯‘æ–‡ã€‘** â€¢	 äººå·¥æ™ºèƒ½ç³»ç»Ÿçš„åˆ›å»ºæˆ–ä½¿ç”¨ä¸å¾—ç”¨äºåœ¨å…¬å…±åœºæ‰€æˆ–åª’ä½“ä¸Šä¸å…¬å¹³åœ°æ“çºµä¸ªäººæˆ–ç¾¤ä½“ï¼Œæˆ–ç”¨äºå…¶ä»–ç±»ä¼¼ç›®çš„ã€‚

---

â€¢	 Artificial intelligence systems must not be created or used to subvert democratic elections or public discourse.

**ã€è¯‘æ–‡ã€‘** â€¢	 äººå·¥æ™ºèƒ½ç³»ç»Ÿçš„åˆ›å»ºæˆ–ä½¿ç”¨ä¸å¾—ç”¨äºç ´åæ°‘ä¸»é€‰ä¸¾æˆ–å…¬å…±è¯è¯­ã€‚

---

â€¢	 Development and deployment of artificial intelligence systems must adhere to the guiding principles, which aims to lessen the environmental impact of business operations.

**ã€è¯‘æ–‡ã€‘** â€¢	 äººå·¥æ™ºèƒ½ç³»ç»Ÿçš„å¼€å‘å’Œéƒ¨ç½²å¿…é¡»éµå®ˆæŒ‡å¯¼åŸåˆ™ï¼Œæ—¨åœ¨å‡å°‘ä¸šåŠ¡è¿è¥å¯¹ç¯å¢ƒçš„å½±å“ã€‚

---

25.3	 Use Case Assessment Process

**ã€è¯‘æ–‡ã€‘** 25.3 ç”¨ä¾‹è¯„ä¼°æµç¨‹

---

As stated in SAP AI Ethics Policy (2022), professionals shall handle ethical problems and trade-offs connected to the usage of artificial intelligence systems through reasoned, context-relevant, and evidence-based decision making rather than through intuition or random discretion.

**ã€è¯‘æ–‡ã€‘** å¦‚ã€ŠSAP AI é“å¾·æ”¿ç­–ï¼ˆ2022ï¼‰ã€‹æ‰€è¿°ï¼Œä¸“ä¸šäººå‘˜åº”é€šè¿‡ç†æ€§çš„ã€ä¸ç¯å¢ƒç›¸å…³çš„å’ŒåŸºäºè¯æ®çš„å†³ç­–ï¼Œè€Œä¸æ˜¯é€šè¿‡ç›´è§‰æˆ–éšæ„çš„è£é‡ï¼Œæ¥å¤„ç†ä¸äººå·¥æ™ºèƒ½ç³»ç»Ÿä½¿ç”¨ç›¸å…³çš„é“å¾·é—®é¢˜å’Œæƒè¡¡ã€‚

---

Teams should first submit the problem for consideration by their unit in cases where a use case presented for an artificial intelligence business application may violate the defined policy at any point in the lifetime or to decide whether or not to pursue the application of a given use case. This holds true even if the teams just have reservations or worries.

**ã€è¯‘æ–‡ã€‘** å¦‚æœæäº¤çš„äººå·¥æ™ºèƒ½å•†ä¸šåº”ç”¨ç”¨ä¾‹å¯èƒ½åœ¨ç”Ÿå‘½å‘¨æœŸçš„ä»»ä½•é˜¶æ®µè¿åæ—¢å®šæ”¿ç­–ï¼Œæˆ–è€…ä¸ºäº†å†³å®šæ˜¯å¦ç»§ç»­æ¨è¿›æŸä¸ªç‰¹å®šç”¨ä¾‹çš„åº”ç”¨ï¼Œå›¢é˜Ÿåº”é¦–å…ˆæäº¤è¯¥é—®é¢˜ä¾›å…¶æ‰€åœ¨å•ä½å®¡è®®ã€‚å³ä½¿å›¢é˜Ÿä»…æŒæœ‰ä¿ç•™æ„è§æˆ–æ‹…å¿§ï¼Œè¿™ä¹Ÿé€‚ç”¨ã€‚

---

25.1

**ã€è¯‘æ–‡ã€‘** 25.1

---

The so-called red lines outlined in the ethics policy should not apply to any artificial intelligence use cases. Under the objectives of artificial intelligence, they are classified as being seriously immoral. We must immediately stop creating, deploying, and selling our use case if it was designed with these goals in mind. Letâ€™s recap the red lines:

**ã€è¯‘æ–‡ã€‘** ä»»ä½•äººå·¥æ™ºèƒ½ç”¨ä¾‹éƒ½ä¸å¾—è§¦åŠé“å¾·æ”¿ç­–ä¸­æ¦‚è¿°çš„æ‰€è°“â€œçº¢çº¿â€ã€‚æ ¹æ®äººå·¥æ™ºèƒ½çš„ç›®æ ‡ï¼Œè¿™äº›è¡Œä¸ºè¢«å½’ç±»ä¸ºä¸¥é‡çš„ä¸é“å¾·è¡Œä¸ºã€‚å¦‚æœæˆ‘ä»¬çš„ç”¨ä¾‹åœ¨è®¾è®¡æ—¶å°±å¸¦æœ‰è¿™äº›ç›®æ ‡ï¼Œæˆ‘ä»¬å¿…é¡»ç«‹å³åœæ­¢åˆ›å»ºã€éƒ¨ç½²å’Œé”€å”®è¯¥ç”¨ä¾‹ã€‚è®©æˆ‘ä»¬å›é¡¾ä¸€ä¸‹è¿™äº›çº¢çº¿ï¼š

---

â€¢	 Personal freedom â€“ human surveillance that uses biometrics, facial recognition, or other distinguishing characteristics to target specific people or groups with the intention of violating or abusing those peopleâ€™s rights. Discrimination that prevents certain people or groups from having equal access to the advantages and opportunities that AI offers to the general community. Data that has already been anonymized is de-anonymized, which could lead to the identification of specific people or groups.

**ã€è¯‘æ–‡ã€‘** â€¢	 ä¸ªäººè‡ªç”± â€”â€” åˆ©ç”¨ç”Ÿç‰©è¯†åˆ«ã€é¢éƒ¨è¯†åˆ«æˆ–å…¶ä»–æ˜¾è‘—ç‰¹å¾è¿›è¡Œäººç±»ç›‘æ§ï¼Œä»¥é’ˆå¯¹ç‰¹å®šäººç¾¤æˆ–ç¾¤ä½“å¹¶æ„å›¾ä¾µçŠ¯æˆ–æ»¥ç”¨è¿™äº›äººçš„æƒåˆ©ã€‚é˜»æ­¢æŸäº›äººæˆ–ç¾¤ä½“å¹³ç­‰è·å¾— AI ä¸ºå¤§ä¼—æä¾›çš„ä¼˜åŠ¿å’Œæœºä¼šçš„æ­§è§†ã€‚å°†å·²ç»åŒ¿ååŒ–çš„æ•°æ®å»åŒ¿ååŒ–ï¼Œä»è€Œå¯èƒ½å¯¼è‡´ç‰¹å®šäººæˆ–ç¾¤ä½“è¢«è¯†åˆ«ã€‚

---

â€¢	 Society â€“ manipulation of people or groups through public forums, the media, or control of other similar purposes with the intention of misleading or unfairly manipulating them. Undercutting democratic electoral systems or discussion methods that undermine human dialogue. Intentional negative effects on system users and/or those who are both directly and indirectly affected by it.

**ã€è¯‘æ–‡ã€‘** â€¢	 ç¤¾ä¼š â€”â€” é€šè¿‡å…¬å…±è®ºå›ã€åª’ä½“æˆ–æ§åˆ¶å…¶ä»–ç±»ä¼¼ç›®çš„æ¥æ“çºµä¸ªäººæˆ–ç¾¤ä½“ï¼Œæ„å›¾è¯¯å¯¼æˆ–ä¸å…¬å¹³åœ°æ“çºµä»–ä»¬ã€‚ç ´åæ°‘ä¸»é€‰ä¸¾åˆ¶åº¦æˆ–ç ´åäººç±»å¯¹è¯çš„è®¨è®ºæ–¹å¼ã€‚å¯¹ç³»ç»Ÿç”¨æˆ·å’Œ/æˆ–ç›´æ¥æˆ–é—´æ¥é€šè¿‡ç³»ç»Ÿå—åˆ°å½±å“çš„äººäº§ç”Ÿæ•…æ„çš„è´Ÿé¢å½±å“ã€‚

---

â€¢	 Environment â€“ development and deployment of artificial intelligence systems must be done with little to no overt environmental damage.

**ã€è¯‘æ–‡ã€‘** â€¢	 ç¯å¢ƒ â€”â€” äººå·¥æ™ºèƒ½ç³»ç»Ÿçš„å¼€å‘å’Œéƒ¨ç½²å¿…é¡»åšåˆ°å‡ ä¹æ²¡æœ‰æˆ–å®Œå…¨æ²¡æœ‰æ˜æ˜¾çš„ç¯å¢ƒç ´åã€‚

---

